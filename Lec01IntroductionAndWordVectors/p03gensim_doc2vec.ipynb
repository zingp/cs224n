{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec\n",
    "- 计算长文本向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"I love you, and you love me.\", \n",
    "    \"I love coding and python.\",\n",
    "    \"they chat anagingly well\",\n",
    "    \"Chapter One The Dark Lord Ascending\",\n",
    "    \"The two men appeared out of nowhere, a few yards apart in the narrow, moonlit lane.\",\n",
    "    \"For a second they stood quite still, wands directed at each other's chests.\"\n",
    "]\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=['SENT_%s' % str(i)])\n",
    "               for i,_d in enumerate(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['i', 'love', 'you', ',', 'and', 'you', 'love', 'me', '.'], tags=['SENT_0']),\n",
       " TaggedDocument(words=['i', 'love', 'coding', 'and', 'python', '.'], tags=['SENT_1']),\n",
       " TaggedDocument(words=['they', 'chat', 'anagingly', 'well'], tags=['SENT_2']),\n",
       " TaggedDocument(words=['chapter', 'one', 'the', 'dark', 'lord', 'ascending'], tags=['SENT_3']),\n",
       " TaggedDocument(words=['the', 'two', 'men', 'appeared', 'out', 'of', 'nowhere', ',', 'a', 'few', 'yards', 'apart', 'in', 'the', 'narrow', ',', 'moonlit', 'lane', '.'], tags=['SENT_4']),\n",
       " TaggedDocument(words=['for', 'a', 'second', 'they', 'stood', 'quite', 'still', ',', 'wands', 'directed', 'at', 'each', 'other', \"'s\", 'chests', '.'], tags=['SENT_5'])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(vector_size=100,\n",
    "                alpha=0.01,\n",
    "                min_count=1,\n",
    "                dm=1)\n",
    "model.build_vocab(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration [0]\n",
      "iteration [1]\n",
      "iteration [2]\n",
      "iteration [3]\n",
      "iteration [4]\n",
      "iteration [5]\n",
      "iteration [6]\n",
      "iteration [7]\n",
      "iteration [8]\n",
      "iteration [9]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    print(\"iteration [{}]\".format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
